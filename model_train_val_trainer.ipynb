{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_H75-IM3yd9"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model, TrainingArguments, Trainer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim import Adam\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "5OM6hKMbQsHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "iTb5Bk_7Qvx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISd4EKBt3yd-"
      },
      "outputs": [],
      "source": [
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPDXAQNw3yd-"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p740djD3yeA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"lyrics_preprocessed.csv\")\n",
        "\n",
        "#assume we have a dataset with two columns - lyrics and mood(numbers 0-3)\n",
        "\n",
        "lyrics = df['lyrics'].values\n",
        "mood = df['Mood_encod'].values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6uRrDm03yeA"
      },
      "outputs": [],
      "source": [
        "# df['lyrics'].shape\n",
        "# df['Mood_encod'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenized_data = tokenizer(df['lyrics'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "# df['Mood_encod'] = df['Mood_encod'].astype(str)\n",
        "# Create a Dataset object\n",
        "dataset = Dataset.from_dict({\n",
        "    'input_ids': tokenized_data['input_ids'],\n",
        "    'attention_mask': tokenized_data['attention_mask'],\n",
        "    'labels': df['Mood_encod'].tolist()  # Assuming Mood_encod contains encoded labels\n",
        "})\n",
        "# dataset.set_format(\"torch\")\n",
        "\n",
        "# dataset = tokenized_data\n",
        "# dataset['labels'] = torch.tensor(df['Mood_encod'].tolist())\n",
        "# Split the dataset into 80% train and 20% validation\n",
        "# train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "CC2nBjuT6TvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.shuffle(seed = 42).select(range(0,1512))\n",
        "val_dataset = dataset.shuffle(seed =42).select(range(1512,1890))"
      ],
      "metadata": {
        "id": "cbCE5Q4IAH87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqiTQ0OR3yeB"
      },
      "outputs": [],
      "source": [
        "#defining classification head\n",
        "\n",
        "class GPT2MoodClassifier(nn.Module):\n",
        "    def __init__(self, gpt2_model, num_classes = 4):\n",
        "        super(GPT2MoodClassifier, self).__init__()\n",
        "        self.gpt2_model = gpt2_model\n",
        "        self.classification_head = nn.Linear(gpt2_model.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.gpt2_model(input_ids, attention_mask = attention_mask)\n",
        "        last_hidden_state = outputs[0]\n",
        "        cls_hidden_state = last_hidden_state[:,0,:]\n",
        "        logits = self.classification_head(cls_hidden_state)\n",
        "        return logits\n",
        "\n",
        "gpt2_model = GPT2Model.from_pretrained(model_name)\n",
        "num_classes = len(set(mood))\n",
        "model = GPT2MoodClassifier(gpt2_model, num_classes = num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIqdbclN3yeB",
        "outputId": "46a30a97-e9c6-4891-c1bf-0ee769e229fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2MoodClassifier(\n",
              "  (gpt2_model): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (classification_head): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers[torch]\n"
      ],
      "metadata": {
        "id": "Y5VBzT7o4SUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate -U"
      ],
      "metadata": {
        "id": "ZVy4Pljh4X84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mthb0J4z3yeB"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "training_args = TrainingArguments(\"checkpoint_path\", num_train_epochs=10, per_device_eval_batch_size=2, \\\n",
        "                                  per_device_train_batch_size=2, evaluation_strategy = \"epoch\", \\\n",
        "                                    gradient_accumulation_steps =4, learning_rate = 1e-3, \\\n",
        "                                        fp16 = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install evaluate"
      ],
      "metadata": {
        "id": "L-3_bGQY5DDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yKY1Muq3yeC"
      },
      "outputs": [],
      "source": [
        "# import evaluate\n",
        "import numpy as np\n",
        "# metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    pred = np.argmax(logits, axis = -1)\n",
        "    return {'accuracy_score': accuracy_score(labels, pred)}\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs = False):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        print(outputs)\n",
        "        loss = nn.CrossEntropyLoss()(outputs,labels)\n",
        "        return (loss,outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEkbiNMM3yeC"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model=model, args = training_args, train_dataset = train_dataset, eval_dataset = val_dataset,\\\n",
        "                  compute_metrics = compute_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "e15R64Nz5R3t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}